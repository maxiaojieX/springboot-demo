server.port=80
spring.application.name=danger
management.security.enabled=false
spring.mvc.static-path-pattern=/static/**

#数据源
# 主数据源，默认的
spring.datasource.type=com.alibaba.druid.pool.DruidDataSource

spring.datasource.primary.url=jdbc:mysql://localhost:3306/qq?useSSL=false&useUnicode=true&characterEncoding=UTF-8
spring.datasource.primary.username=root
spring.datasource.primary.password=123123
spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver
spring.datasource.primary.filters=stat,wall
spring.datasource.primary.initialSize=1
spring.datasource.primary.minIdle=1
spring.datasource.primary.maxActive=1
# 配置获取连接等待超时的时间
spring.datasource.primary.maxWait=3000
# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
spring.datasource.primary.timeBetweenEvictionRunsMillis=60000
# 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.primary.minEvictableIdleTimeMillis=300000
spring.datasource.primary.validationQuery=SELECT 1 FROM DUAL
spring.datasource.primary.testWhileIdle=true
spring.datasource.primary.testOnBorrow=false
# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
spring.datasource.filters=stat,wall
# 通过connectProperties属性来打开mergeSql功能；慢SQL记录
spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
# 合并多个DruidDataSource的监控数据
spring.datasource.useGlobalDataSourceStat=true

#mybatis
mybatis.type-aliases-package=com.danger.bean
mybatis.mapper-locations=classpath:mapper/*.xml

#redis
spring.redis.host=119.27.161.212
spring.redis.port=6379
spring.redis.password=maxiaojie
spring.redis.database=0
spring.redis.pool.max-active=2
spring.redis.pool.max-wait=-1
spring.redis.pool.max-idle=2
spring.redis.pool.min-idle=2
spring.redis.timeout=3000

##============== kafka ===================
## 指定kafka 代理地址，可以多个
#spring.kafka.bootstrap-servers=119.27.161.212:9092
##=============== provider  =======================
#spring.kafka.producer.retries=0
## 每次批量发送消息的数量
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
## 指定消息key和消息体的编解码方式
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
##=============== consumer  =======================
## 指定默认消费者group id
#spring.kafka.consumer.group-id=test-consumer-group
#spring.kafka.consumer.auto-offset-reset=earliest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
## 指定消息key和消息体的编解码方式
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer

##kafka相关配置
#spring.kafka.bootstrap-servers=119.27.161.212:9092
##设置一个默认组
#spring.kafka.consumer.group-id=test-consumer-group
##key-value序列化反序列化
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.batch-size=65536
#spring.kafka.producer.buffer-memory=524288

#============== kafka ===================
kafka.consumer.zookeeper.connect=119.27.161.212:2181
kafka.consumer.servers=119.27.161.212:9092
kafka.consumer.enable.auto.commit=true
kafka.consumer.session.timeout=6000
kafka.consumer.auto.commit.interval=100
kafka.consumer.auto.offset.reset=latest
kafka.consumer.topic=mytest-topic
kafka.consumer.group.id=test-consumer-group
kafka.consumer.concurrency=10

kafka.producer.servers=119.27.161.212:9092
kafka.producer.retries=0
kafka.producer.batch.size=4096
kafka.producer.linger=1
kafka.producer.buffer.memory=40960